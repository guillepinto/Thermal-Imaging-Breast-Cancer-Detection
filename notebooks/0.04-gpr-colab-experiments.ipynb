{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dftDiCQg3vYy"
      },
      "source": [
        "# <font color='#4C5FDA'>**Breast Cancer Detection Based on CNNs Using Thermal Imaging** </font>\n",
        "\n",
        "Original paper by Juan Pablo Zuluaga, Zeina Al Masry, Khaled Benaggoune, Safa Meraghni & Noureddine Zerhouni: [A CNN-based methodology for breast cancer diagnosis using thermal images](https://www.tandfonline.com/doi/full/10.1080/21681163.2020.1824685)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uraq36CkXB1T",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Instalar paquetes necesarios**\n",
        "\n",
        "%%capture\n",
        "! pip install torchmetrics\n",
        "! pip install wandb -Uq\n",
        "# ! pip install onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#ECA702'>**Clonamos nuestro repo**</font>\n",
        "\n",
        "Esto con el fin de traer todos los .py para poder entrenar 'localmente' en Colab y registrar las m茅tricas en wandb."
      ],
      "metadata": {
        "id": "3eUcjX2Lv5g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/gpintoruiz/Thermal-Imaging-Breast-Cancer-Detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miS2W9Tdwbxq",
        "outputId": "aa1a3135-9a4e-49c1-aee6-43d1bec5eb4f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Thermal-Imaging-Breast-Cancer-Detection'...\n",
            "remote: Enumerating objects: 380, done.\u001b[K\n",
            "remote: Counting objects: 100% (160/160), done.\u001b[K\n",
            "remote: Compressing objects: 100% (126/126), done.\u001b[K\n",
            "remote: Total 380 (delta 99), reused 70 (delta 34), pack-reused 220\u001b[K\n",
            "Receiving objects: 100% (380/380), 7.78 MiB | 33.18 MiB/s, done.\n",
            "Resolving deltas: 100% (226/226), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Thermal-Imaging-Breast-Cancer-Detection/notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMuOAySxx1Z1",
        "outputId": "9aff97dd-c604-433d-95ea-f7510ad920f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssFb9A5GyA_u",
        "outputId": "7979d595-dd85-42eb-fdd4-ea30dd3b7363"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01-gpr-data-exploration-cv2.ipynb   alexnet.py       train_gkfold.py   vgg.py\n",
            "0.01-gpr-data-exploration-pil.ipynb   make_dataset.py  train_one_run.py  xception-gfkfold.yaml\n",
            "0.04-gpr-colab-experiments.ipynb      preprocess.py    train.py          xception-one-run.yaml\n",
            "1.00-gpr-xception-from-scratch.ipynb  test.py          utils.py          xception.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkrHeEps3vY3"
      },
      "source": [
        "## <font color='#ECA702'>**Configuraci贸n inicial para conectarnos con Kaggle**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJFg6k1x3vY5"
      },
      "source": [
        "1. Instalamos kaggle. Para poder usar comandos de Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hwqionQb3vY6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP3nl2Et3vY7"
      },
      "source": [
        "Subimos nuestro token de autenticaci贸n de Kaggle (si estamos en colab, sino colocarlo en la carpeta del proyecto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARP6wZsb3vY8"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0VPkGso3vY9"
      },
      "source": [
        "1. Creamos los directorios de Kaggle\n",
        "2. Copiamos nuestro token en .kaggle\n",
        "3. Con `chmod 600` establecemos los permitos del token en 600, es decir, que solo yo tengo permisos de lectura y escritura sobre el archivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ed2nCVTu3vY-"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UhQ_SI9x3vZA"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGkGIazz3vZB"
      },
      "source": [
        "## <font color='#ECA702'>**Carga del dataset**</font>\n",
        "\n",
        "Traemos el dataset [Thermal Images for Breast Cancer Diagnosis DMR-IR](https://www.kaggle.com/datasets/asdeepak/thermal-images-for-breast-cancer-diagnosis-dmrir) desde kaggle.\n",
        "\n",
        "This dataset is a methodology for breast disease computer-aided diagnosis using dynamic thermography. The thermal images for breast tumors are classified according to DMR-IR standards.\n",
        "\n",
        "Two types of tumors are classified in this dataset one is benign another is malignant.\n",
        "- Benign: This type of tumor is usually well-defined and round or oval in shape. (non-cancerous tumor)\n",
        "- Malignant: This type of tumor is usually poorly defined and irregular with lobules. (cancerous tumor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "lmT0aOvG3vZD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! kaggle datasets download -d asdeepak/thermal-images-for-breast-cancer-diagnosis-dmrir\n",
        "! unzip thermal-images-for-breast-cancer-diagnosis-dmrir.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QToIa8zB3vZE"
      },
      "source": [
        "Despu茅s de descargar los datos. Debemos entender la estructura de las carpetas para poder trabajar con ellas de una mejor manera.\n",
        "1. La carpeta principal `Imagens e Matrizes da Tese de Thiago Alves Elias da Silva` son todos los datos `data`.\n",
        "2. La carpeta `12 Novos Casos de Testes` la podemos tomar como nuestro conjunto de prueba (`test`).\n",
        "3. Mientras que la carpeta `Desenvolvimento da Metodologia` ser谩 nuestro conjunto de entrenamiento (`train`).\n",
        "\n",
        "Luego dentro de nuestras carpetas de `train` y `test` encontramos dos categor铆as `DOENTES`y `SAUDA啸邪VEIS` o SAUDVEI. Los primeros son los casos malignos y los segundos benignos.\n",
        "\n",
        "Dentro de cada una de las carpetas de pacientes saludables y enfermos se encuentran carpetas con n煤meros, cada n煤mero representa un paciente. Y para cada paciente tendremos dos carpetas m谩s, una para las im谩genes **segmentadas** en escala de grises y la otra para la matrix o mapa de calor.\n",
        "\n",
        "Algo bueno de este dataset es que ya est谩 dividido por pacientes, es decir, no tendremos imagenes del mismo paciente en el conjunto de entrenamiento y testeo. Por lo tanto, vamos a entrenar con N pacientes, y testear con K pacientes, que no son los mismos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#52F17F'>**Partici贸n de los datos**</font>"
      ],
      "metadata": {
        "id": "gvB-mHCPqELO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este comando nos permite cargar funciones de un .py en el entorno local de Colab. [Fuente](https://stackoverflow.com/questions/47345004/in-googles-colab-notebook-how-do-i-call-a-function-from-a-python-file)"
      ],
      "metadata": {
        "id": "753-jlzfrNz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "execfile('make_dataset.py')"
      ],
      "metadata": {
        "id": "0jIUw7ntqHQU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2024)\n",
        "\n",
        "def print_fold_patients(folds: dict, data: pd.DataFrame):\n",
        "    for fold_name, indices in folds.items():\n",
        "        train_patients = data.iloc[indices['train']]['patient'].unique()\n",
        "        # val_patients = data.iloc[indices['val']]['patient'].unique()\n",
        "        test_patients = data.iloc[indices['test']]['patient'].unique()\n",
        "\n",
        "        print(f\"{fold_name}:\\n\")\n",
        "        print(f\"Train patients: {train_patients}\")\n",
        "        # print(f\"Validation patients: {val_patients}\")\n",
        "        print(f\"Test patients: {test_patients}\\n\")\n",
        "\n",
        "# Generar los datos\n",
        "data = make_dataframe()\n",
        "\n",
        "# Generar los folds\n",
        "folds = make_folds(data)\n",
        "\n",
        "# Imprimir los pacientes por cada fold\n",
        "print_fold_patients(folds, data)"
      ],
      "metadata": {
        "id": "wI2woWQCqxcO",
        "outputId": "f873cbba-c425-43b6-9bc8-c73a604a4110",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold_1:\n",
            "\n",
            "Train patients: ['66' '62' '61' '63' '64' '65' '14' '48' '69' '28' '04' '29' '00' '59'\n",
            " '35' '36' '58' '01' '56' '05' '53' '32' '51' '49' '55' '24' '02' '25'\n",
            " '31' '08' '07' '54' '26' '09' '38' '45' '13' '44' '11' '42' '15' '16'\n",
            " '40' '43' '39' '37' '46' '41']\n",
            "Test patients: ['03' '06' '60' '27' '30' '52' '34' '17']\n",
            "\n",
            "fold_2:\n",
            "\n",
            "Train patients: ['66' '62' '61' '63' '64' '65' '14' '28' '04' '03' '29' '00' '35' '06'\n",
            " '36' '60' '58' '01' '05' '53' '32' '49' '27' '55' '24' '02' '25' '31'\n",
            " '08' '54' '30' '52' '09' '38' '45' '13' '44' '11' '42' '15' '16' '40'\n",
            " '34' '43' '39' '17' '37' '46']\n",
            "Test patients: ['48' '69' '59' '56' '51' '07' '26' '41']\n",
            "\n",
            "fold_3:\n",
            "\n",
            "Train patients: ['66' '62' '61' '63' '64' '14' '48' '69' '28' '04' '03' '29' '00' '59'\n",
            " '35' '06' '36' '60' '56' '05' '53' '32' '51' '27' '55' '24' '02' '25'\n",
            " '31' '07' '54' '30' '52' '26' '09' '38' '45' '13' '44' '11' '40' '34'\n",
            " '43' '39' '17' '37' '46' '41']\n",
            "Test patients: ['65' '58' '01' '49' '08' '42' '15' '16']\n",
            "\n",
            "fold_4:\n",
            "\n",
            "Train patients: ['62' '61' '63' '65' '14' '48' '69' '28' '04' '03' '29' '00' '59' '35'\n",
            " '06' '36' '60' '58' '01' '56' '05' '53' '32' '51' '49' '27' '24' '02'\n",
            " '31' '08' '07' '54' '30' '52' '26' '38' '45' '44' '11' '42' '15' '16'\n",
            " '40' '34' '39' '17' '46' '41']\n",
            "Test patients: ['66' '64' '55' '25' '09' '13' '43' '37']\n",
            "\n",
            "fold_5:\n",
            "\n",
            "Train patients: ['66' '62' '61' '64' '65' '14' '48' '69' '28' '04' '03' '00' '59' '06'\n",
            " '36' '60' '58' '01' '56' '05' '53' '32' '51' '49' '27' '55' '02' '25'\n",
            " '08' '07' '54' '30' '52' '26' '09' '45' '13' '42' '15' '16' '40' '34'\n",
            " '43' '39' '17' '37' '46' '41']\n",
            "Test patients: ['63' '29' '35' '24' '31' '38' '44' '11']\n",
            "\n",
            "fold_6:\n",
            "\n",
            "Train patients: ['66' '61' '63' '64' '65' '48' '69' '04' '03' '29' '00' '59' '35' '06'\n",
            " '36' '60' '58' '01' '56' '53' '51' '49' '27' '55' '24' '02' '25' '31'\n",
            " '08' '07' '30' '52' '26' '09' '38' '13' '44' '11' '42' '15' '16' '40'\n",
            " '34' '43' '17' '37' '46' '41']\n",
            "Test patients: ['62' '14' '28' '05' '32' '54' '45' '39']\n",
            "\n",
            "fold_7:\n",
            "\n",
            "Train patients: ['66' '62' '63' '64' '65' '14' '48' '69' '28' '03' '29' '59' '35' '06'\n",
            " '60' '58' '01' '56' '05' '32' '51' '49' '27' '55' '24' '25' '31' '08'\n",
            " '07' '54' '30' '52' '26' '09' '38' '45' '13' '44' '11' '42' '15' '16'\n",
            " '34' '43' '39' '17' '37' '41']\n",
            "Test patients: ['61' '04' '00' '36' '53' '02' '40' '46']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#ECA702'>**Inicializamos el agende de wandb**</font>"
      ],
      "metadata": {
        "id": "5YTKbsdDyqSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#52F17F'>**1. Nos logeamos en nuestra cuenta**</font>"
      ],
      "metadata": {
        "id": "nIskv2fHy4Qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "St3agN3Rypzq",
        "outputId": "448f91d7-daad-4ee9-90cb-095634624d08"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 路路路路路路路路路路\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#52F17F'>**2. Hacemos call del agente**</font>\n"
      ],
      "metadata": {
        "id": "w0r-E8Ufy9TQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El sweep que estoy probando ac谩 es el [siguiente](https://github.com/gpintoruiz/Thermal-Imaging-Breast-Cancer-Detection/blob/main/notebooks/xception-one-run.yaml). Se pueden cambiar los par谩metros a probar como t煤 quieras de acuerdo con la [documentaci贸n](https://docs.wandb.ai/guides/sweeps/define-sweep-configuration) (recomiendo solo cambiar la arquitectura para que las comparaciones entre modelos sean equivalentes).\n",
        "\n",
        "Si no tienes ni idea qu茅 es un sweep mira el siguiente [tutorial](https://www.youtube.com/watch?v=9zrmUIlScdY&t=1361s&ab_channel=Weights%26Biases).\n",
        "\n",
        "El comando `--count` sirve para decirle al agente cu谩ntos runs hacer, aplica especialmente cuando el m茅todo del sweep es `bayes` o `random`\n"
      ],
      "metadata": {
        "id": "LxtyncVoCVL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wandb agent aiuis/dip-project/80af0iqh --count 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpG6dTZdy0R3",
        "outputId": "d7237df9-c591-4457-9f4e-ab19b38ed5d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 碉\n",
            "2024-06-30 20:04:26,892 - wandb.wandb_agent - INFO - Running runs: []\n",
            "2024-06-30 20:04:37,223 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2024-06-30 20:04:37,223 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tarchitecture: xception\n",
            "\taugmented: True\n",
            "\tbatch_size: 64\n",
            "\tcrop: True\n",
            "\tlearning_rate: 0.0008357465887034653\n",
            "\tnormalize: True\n",
            "\toptimizer: sgd\n",
            "2024-06-30 20:04:37,225 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train_one_run.py --architecture=xception --augmented=True --batch_size=64 --crop=True --learning_rate=0.0008357465887034653 --normalize=True --optimizer=sgd\n",
            "2024-06-30 20:04:42,237 - wandb.wandb_agent - INFO - Running runs: ['9khc3omb']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgpintoruiz\u001b[0m (\u001b[33maiuis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks/wandb/run-20240630_200442-9khc3omb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mearnest-sweep-7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 猸锔 View project at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ч View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/sweeps/80af0iqh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/9khc3omb\u001b[0m\n",
            "FOLD 4\n",
            "-------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "train loss: 0.679 accuracy: 0.522 [after 4 batches]\n",
            "train loss: 0.683 accuracy: 0.516 [after 9 batches]\n",
            "train loss: 0.680 accuracy: 0.544 [after 14 batches]\n",
            "train loss: 0.674 accuracy: 0.564 [after 19 batches]\n",
            "test loss: 0.689 accuracy: 0.544 recall: 0.000 precision: 0.000 f1: 0.000 [after 4 batches]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train loss: 0.615 accuracy: 0.634 [after 4 batches]\n",
            "train loss: 0.612 accuracy: 0.633 [after 9 batches]\n",
            "train loss: 0.599 accuracy: 0.658 [after 14 batches]\n",
            "train loss: 0.581 accuracy: 0.682 [after 19 batches]\n",
            "test loss: 0.807 accuracy: 0.534 recall: 0.000 precision: 0.000 f1: 0.000 [after 4 batches]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train loss: 0.458 accuracy: 0.794 [after 4 batches]\n",
            "train loss: 0.410 accuracy: 0.830 [after 9 batches]\n",
            "train loss: 0.384 accuracy: 0.849 [after 14 batches]\n",
            "train loss: 0.352 accuracy: 0.868 [after 19 batches]\n",
            "test loss: 0.469 accuracy: 0.781 recall: 0.578 precision: 0.930 f1: 0.705 [after 4 batches]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train loss: 0.274 accuracy: 0.903 [after 4 batches]\n",
            "train loss: 0.233 accuracy: 0.927 [after 9 batches]\n",
            "train loss: 0.235 accuracy: 0.922 [after 14 batches]\n",
            "train loss: 0.235 accuracy: 0.918 [after 19 batches]\n",
            "test loss: 0.341 accuracy: 0.860 recall: 0.786 precision: 0.893 f1: 0.835 [after 4 batches]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train loss: 0.242 accuracy: 0.906 [after 4 batches]\n",
            "train loss: 0.211 accuracy: 0.927 [after 9 batches]\n",
            "train loss: 0.213 accuracy: 0.926 [after 14 batches]\n",
            "train loss: 0.222 accuracy: 0.920 [after 19 batches]\n",
            "test loss: 0.329 accuracy: 0.899 recall: 0.785 precision: 1.000 f1: 0.877 [after 4 batches]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train loss: 0.169 accuracy: 0.950 [after 4 batches]\n",
            "train loss: 0.192 accuracy: 0.941 [after 9 batches]\n",
            "train loss: 0.200 accuracy: 0.928 [after 14 batches]\n",
            "train loss: 0.200 accuracy: 0.926 [after 19 batches]\n",
            "test loss: 0.484 accuracy: 0.729 recall: 0.797 precision: 0.666 f1: 0.723 [after 4 batches]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train loss: 0.240 accuracy: 0.906 [after 4 batches]\n",
            "train loss: 0.205 accuracy: 0.923 [after 9 batches]\n",
            "train loss: 0.206 accuracy: 0.921 [after 14 batches]\n",
            "train loss: 0.202 accuracy: 0.922 [after 19 batches]\n",
            "test loss: 0.612 accuracy: 0.658 recall: 0.782 precision: 0.591 f1: 0.673 [after 4 batches]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train loss: 0.174 accuracy: 0.944 [after 4 batches]\n",
            "train loss: 0.180 accuracy: 0.936 [after 9 batches]\n",
            "train loss: 0.177 accuracy: 0.940 [after 14 batches]\n",
            "train loss: 0.185 accuracy: 0.939 [after 19 batches]\n",
            "test loss: 0.363 accuracy: 0.903 recall: 0.788 precision: 1.000 f1: 0.881 [after 4 batches]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train loss: 0.200 accuracy: 0.931 [after 4 batches]\n",
            "train loss: 0.183 accuracy: 0.934 [after 9 batches]\n",
            "train loss: 0.173 accuracy: 0.940 [after 14 batches]\n",
            "train loss: 0.172 accuracy: 0.941 [after 19 batches]\n",
            "test loss: 0.591 accuracy: 0.662 recall: 0.813 precision: 0.602 f1: 0.688 [after 4 batches]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "train loss: 0.160 accuracy: 0.950 [after 4 batches]\n",
            "train loss: 0.168 accuracy: 0.941 [after 9 batches]\n",
            "train loss: 0.175 accuracy: 0.935 [after 14 batches]\n",
            "train loss: 0.180 accuracy: 0.933 [after 19 batches]\n",
            "test loss: 0.490 accuracy: 0.702 recall: 0.833 precision: 0.635 f1: 0.720 [after 4 batches]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "train loss: 0.120 accuracy: 0.966 [after 4 batches]\n",
            "train loss: 0.181 accuracy: 0.933 [after 9 batches]\n",
            "train loss: 0.153 accuracy: 0.946 [after 14 batches]\n",
            "train loss: 0.156 accuracy: 0.942 [after 19 batches]\n",
            "test loss: 0.411 accuracy: 0.803 recall: 0.802 precision: 0.767 f1: 0.783 [after 4 batches]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "train loss: 0.210 accuracy: 0.925 [after 4 batches]\n",
            "train loss: 0.189 accuracy: 0.923 [after 9 batches]\n",
            "train loss: 0.178 accuracy: 0.929 [after 14 batches]\n",
            "train loss: 0.163 accuracy: 0.938 [after 19 batches]\n",
            "test loss: 0.356 accuracy: 0.893 recall: 0.763 precision: 0.990 f1: 0.854 [after 4 batches]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "train loss: 0.172 accuracy: 0.938 [after 4 batches]\n",
            "train loss: 0.157 accuracy: 0.945 [after 9 batches]\n",
            "train loss: 0.169 accuracy: 0.940 [after 14 batches]\n",
            "train loss: 0.164 accuracy: 0.942 [after 19 batches]\n",
            "test loss: 0.440 accuracy: 0.804 recall: 0.801 precision: 0.782 f1: 0.789 [after 4 batches]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "train loss: 0.120 accuracy: 0.966 [after 4 batches]\n",
            "train loss: 0.145 accuracy: 0.959 [after 9 batches]\n",
            "train loss: 0.158 accuracy: 0.955 [after 14 batches]\n",
            "train loss: 0.150 accuracy: 0.952 [after 19 batches]\n",
            "test loss: 0.422 accuracy: 0.812 recall: 0.872 precision: 0.739 f1: 0.793 [after 4 batches]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "train loss: 0.159 accuracy: 0.944 [after 4 batches]\n",
            "train loss: 0.147 accuracy: 0.948 [after 9 batches]\n",
            "train loss: 0.141 accuracy: 0.953 [after 14 batches]\n",
            "train loss: 0.147 accuracy: 0.953 [after 19 batches]\n",
            "test loss: 0.427 accuracy: 0.789 recall: 0.804 precision: 0.774 f1: 0.778 [after 4 batches]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step 59\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.7885\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 0.77825\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision 0.77416\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall 0.80421\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.95312\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.14748\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run \u001b[33mearnest-sweep-7\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/9khc3omb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 猸锔 View project at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240630_200442-9khc3omb/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "2024-06-30 20:22:56,175 - wandb.wandb_agent - INFO - Cleaning up finished run: 9khc3omb\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}